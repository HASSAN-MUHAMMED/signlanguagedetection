{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa040d4-2a6a-4c68-87aa-18bfe9340444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Letter: A\n",
      "Saved Letter: C\n",
      "Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Jun/2025 23:06:12] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Space.\n",
      "Added Space.\n",
      "Deleted Letter:  \n",
      "Deleted Letter:  \n",
      "Deleted Letter: C\n",
      "Deleted Letter: A\n",
      "No letter to delete.\n",
      "No letter to delete.\n",
      "No letter to delete.\n",
      "No letter to delete.\n",
      "No letter to delete.\n",
      "No letter to delete.\n",
      "No letter to delete.\n",
      "Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Jun/2025 23:12:45] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Letter: P\n",
      "Saved Letter: P\n",
      "Saved Letter: H\n",
      "Saved Letter: Y\n",
      "Saved Letter: A\n",
      "Saved Letter: A\n",
      "Saved Letter: P\n",
      "Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Jun/2025 23:15:24] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Letter: A\n",
      "Saved Letter: A\n",
      "Saved Letter: P\n",
      "Saved Letter: Y\n",
      "Saved Letter: K\n",
      "Saved Letter: L\n",
      "Saved Letter: L\n",
      "Final Sentence Printed: PPHYAAPAAPYKLL\n",
      "Saved Letter: A\n",
      "Saved Letter: A\n",
      "Saved Letter: P\n",
      "Saved Letter: K\n",
      "Saved Letter: A\n",
      "Deleted Letter: A\n",
      "Deleted Letter: K\n",
      "Deleted Letter: P\n",
      "Deleted Letter: A\n",
      "Final Sentence Printed: A\n",
      "Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Jun/2025 23:17:04] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, Response\n",
    "from flask_cors import CORS\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import threading\n",
    "\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Load trained model\n",
    "model_dict = pickle.load(open('./model.p', 'rb'))\n",
    "model = model_dict['model']\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "# Labels dictionary for predictions\n",
    "labels_dict = {i: chr(65 + i) for i in range(26)}\n",
    "\n",
    "# List to store detected letters and form the sentence\n",
    "sentence = []\n",
    "current_letter = \"?\"  # Track the current detected letter\n",
    "final_sentence = \"\"  # Store the printed sentence\n",
    "\n",
    "\n",
    "def generate_frames():\n",
    "    global current_letter, sentence, final_sentence  # Access global variables\n",
    "    cap = cv2.VideoCapture(0)  # Open camera\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert to RGB for MediaPipe processing\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        # Default to \"?\" if no hand is detected\n",
    "        current_letter = \"?\"\n",
    "\n",
    "        # If hand landmarks are detected, predict the character\n",
    "        if results.multi_hand_landmarks:\n",
    "            landmarks = results.multi_hand_landmarks[0]\n",
    "            data_aux = []\n",
    "\n",
    "            x_, y_ = [lm.x for lm in landmarks.landmark], [lm.y for lm in landmarks.landmark]\n",
    "            for lm in landmarks.landmark:\n",
    "                data_aux.append(lm.x - min(x_))\n",
    "                data_aux.append(lm.y - min(y_))\n",
    "\n",
    "            # Ensure proper data length for model input\n",
    "            data_aux = data_aux[:42] + [0] * max(0, 42 - len(data_aux))\n",
    "            prediction = model.predict([np.asarray(data_aux)])\n",
    "            current_letter = labels_dict.get(int(prediction[0]), \"?\")\n",
    "\n",
    "        # Add the current forming sentence, detected letter, and final sentence to the video frame\n",
    "        cv2.putText(frame, f\"Current Letter: {current_letter}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 255), 3)\n",
    "        cv2.putText(frame, \"Forming Sentence: \" + \"\".join(sentence), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Final Sentence: \" + final_sentence, (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Sign Language Detection\", frame)\n",
    "\n",
    "        # Listen for key presses\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('k'):  # Save the detected letter\n",
    "            if current_letter != \"?\":\n",
    "                sentence.append(current_letter)\n",
    "                print(f\"Saved Letter: {current_letter}\")\n",
    "        elif key == ord('s'):  # Add a space\n",
    "            sentence.append(\" \")\n",
    "            print(\"Added Space.\")\n",
    "        elif key == ord('d'):  # Delete the last letter (Backspace functionality)\n",
    "            if sentence:\n",
    "                deleted_letter = sentence.pop()\n",
    "                print(f\"Deleted Letter: {deleted_letter}\")\n",
    "            else:\n",
    "                print(\"No letter to delete.\")\n",
    "        elif key == ord('p'):  # Print the final sentence on screen and reset `sentence`\n",
    "            final_sentence = \"\".join(sentence)\n",
    "            print(f\"Final Sentence Printed: {final_sentence}\")\n",
    "            sentence = []  # Clear the forming sentence after printing\n",
    "        elif key == ord('q'):  # Quit the loop and stop the program\n",
    "            print(\"Exiting...\")\n",
    "            \n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "@app.route('/video_feed')\n",
    "\n",
    "def video_feed():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "# Run Flask app in a separate thread\n",
    "def run_app():\n",
    "    app.run(debug=True, use_reloader=False)\n",
    "\n",
    "flask_thread = threading.Thread(target=run_app)\n",
    "flask_thread.start()\n",
    "\n",
    "# Run video capture and key detection in the main thread\n",
    "# generate_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a643c39-a484-4642-a36b-a21a687f1a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8ee63-f514-4bc0-a3ab-9e4eeb7a6ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548003c2-c713-4447-b4f3-8a2e746e876d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0d8024-9a86-40a8-9bae-7e5379f4d1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask-cors in c:\\users\\omar\\anaconda3\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: flask>=0.9 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from flask-cors) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from flask-cors) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from flask>=0.9->flask-cors) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from flask>=0.9->flask-cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from flask>=0.9->flask-cors) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from flask>=0.9->flask-cors) (1.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from Werkzeug>=0.7->flask-cors) (2.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\omar\\anaconda3\\lib\\site-packages (from click>=8.1.3->flask>=0.9->flask-cors) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8571000-b0a0-48fb-9d54-17abef1ec512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc326f05-a23b-4265-911c-3ca8df011f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n",
      "Saved Letter: H\n",
      "Saved Letter: E\n",
      "Saved Letter: L\n",
      "Saved Letter: L\n",
      "Saved Letter: O\n",
      "Final Sentence Printed: HELLO\n",
      "Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Jun/2025 13:04:37] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Jun/2025 13:14:29] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, Response\n",
    "from flask_cors import CORS\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import threading\n",
    "\n",
    "# Initialize Flask web app\n",
    "app = Flask(__name__)  # Fixed typo: \"_name_\" should be \"__name__\"\n",
    "CORS(app)  # Enable Cross-Origin Resource Sharing (CORS)\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_dict = pickle.load(open('./model.p', 'rb'))  # Load model from pickle file\n",
    "model = model_dict['model']\n",
    "\n",
    "# Initialize MediaPipe for hand detection and drawing\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils  # For drawing landmarks and connections\n",
    "\n",
    "# Create a dictionary that maps model predictions (0–25) to letters A–Z\n",
    "labels_dict = {i: chr(65 + i) for i in range(26)}\n",
    "\n",
    "# Variables to track the current state\n",
    "sentence = []          # Letters forming the sentence\n",
    "current_letter = \"?\"   # Currently predicted letter\n",
    "final_sentence = \"\"    # Final complete sentence\n",
    "\n",
    "# Function to capture video frames and process hand gestures\n",
    "def generate_frames():\n",
    "    global current_letter, sentence, final_sentence\n",
    "    cap = cv2.VideoCapture(0)  # Open webcam\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame from BGR to RGB for MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)  # Process the frame to detect hands\n",
    "\n",
    "        current_letter = \"?\"\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "            # Draw hand landmarks and connections\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "                    mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "                )\n",
    "\n",
    "            # Prepare data for prediction\n",
    "            data_aux = []\n",
    "            x_, y_ = [lm.x for lm in landmarks.landmark], [lm.y for lm in landmarks.landmark]\n",
    "            for lm in landmarks.landmark:\n",
    "                data_aux.append(lm.x - min(x_))\n",
    "                data_aux.append(lm.y - min(y_))\n",
    "\n",
    "            # Ensure the input size matches expected size for the model (padding if necessary)\n",
    "            data_aux = data_aux[:42] + [0] * max(0, 42 - len(data_aux))\n",
    "            prediction = model.predict([np.asarray(data_aux)])  # Predict gesture\n",
    "            current_letter = labels_dict.get(int(prediction[0]), \"?\")  # Map prediction to letter\n",
    "\n",
    "        # Overlay current state on the frame\n",
    "        cv2.putText(frame, f\"Current Letter: {current_letter}\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 255), 3)\n",
    "        cv2.putText(frame, \"Forming Sentence: \" + \"\".join(sentence), (50, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Final Sentence: \" + final_sentence, (50, 150),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the processed frame\n",
    "        cv2.imshow(\"Sign Language Detection\", frame)\n",
    "\n",
    "        # Handle keyboard inputs:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('k'):\n",
    "            if current_letter != \"?\":\n",
    "                sentence.append(current_letter)  # Save current letter\n",
    "                print(f\"Saved Letter: {current_letter}\")\n",
    "        elif key == ord('s'):\n",
    "            sentence.append(\" \")  # Add space\n",
    "            print(\"Added Space.\")\n",
    "        elif key == ord('d'):\n",
    "            if sentence:\n",
    "                deleted_letter = sentence.pop()  # Delete last letter\n",
    "                print(f\"Deleted Letter: {deleted_letter}\")\n",
    "            else:\n",
    "                print(\"No letter to delete.\")\n",
    "        elif key == ord('p'):\n",
    "            final_sentence = \"\".join(sentence)  # Finalize sentence\n",
    "            print(f\"Final Sentence Printed: {final_sentence}\")\n",
    "            sentence = []\n",
    "        elif key == ord('q'):\n",
    "            print(\"Exiting...\")  # Quit the loop\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Flask route to serve the video feed\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "# Function to run the Flask app in a separate thread\n",
    "def run_app():\n",
    "    app.run(debug=False, use_reloader=False)\n",
    "\n",
    "# Start Flask server in a background thread\n",
    "flask_thread = threading.Thread(target=run_app)\n",
    "flask_thread.start()\n",
    "\n",
    "# Start gesture detection loop in the main thread\n",
    "generate_frames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3491206-5c57-467c-80df-3f46be5c55c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb0b8e-9fd6-4d99-8f94-e50ecf9e99e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787f60c-6035-4cab-b699-baeeab83954a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647a117-bf9e-40fa-b236-b241d8da4b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639456c6-1b0d-4618-8e04-28ce25effe75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd297c36-6a89-47e5-8b8c-0cfb3973b8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41880038-62e1-4172-9f6b-0323b2803561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5560b-75ab-4d08-aea5-19ab569668fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17462054-1bb0-4a1a-ab2d-91725514498a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10736947-8d88-44df-ac5a-368ff5cd950b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6eafce-3c12-482f-ab86-545a8cbd7e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bdac9-8650-4105-96a7-abb734b729b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c007b5a-3bca-44ed-ac6e-434c6336220b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dde3ae-903b-450c-a6d5-e52d20623b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936bc781-d829-455a-b7f5-f603f8fc9bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08adb8-05b6-4b17-a8b1-6149143bdd16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844dafd-b61e-4d15-9a59-d451a8a02084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b80e0-7b8b-4420-849e-0e2516f5f786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2b728-92f3-42f9-8ec6-b01a782a63f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aac7f3-b3c4-4286-a934-42af101208b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58496aa9-3315-4ee5-a042-812488df34a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2fa92-7e71-4ed1-84d2-2a0bf3cd3827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0cfaf-e895-43f6-8923-74bd27a3162d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d80dcf-d6ed-4664-9eb6-fe8883220788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea769eac-40c4-4e8b-b341-4e87aa4b1f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd69a42-dc54-44e0-9ea2-c629af47fd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f332d38-de16-4164-8e8a-2f251ee38db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e0aef-26fa-45d9-ae60-e268fcff0554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711765ab-ef40-4a11-a1ee-0b4e6cc93203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e02736-fe40-47aa-9527-469674aeefb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d6409-0bb1-4c74-b256-58fe074e5946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df7e79-f4fa-4398-898d-ff95ca0976b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8d2a3-6811-421a-94f5-5a113c548897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79860f-2265-49af-8c51-f1fc6060b66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063c9c9-07d2-4266-be95-65680df7fc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6bb0b-7c42-4068-8702-7561f5fcea70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736e65b-c687-4a53-8a46-bddfef1587fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356bfd2-0064-4b69-b29b-cc21031bf80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d066086-f5c0-4a38-bfcc-e6b0482b13b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637f785-df64-418e-9280-890aee8da578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4063b302-8c7a-4586-a15c-aa9cdeb2e898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72aecdb-4636-4d39-911b-7bd632ea8a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de5f84-d6f5-4677-acb4-a28415e01ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39461d4-ada1-47e8-9012-99672fc5d449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b3dcd-b982-4f02-a454-f506461f653f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f4001-2614-4b32-807f-8bc062a761df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91770fcf-f1ad-4f71-bfcf-e344d3c2b1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057308cd-99d6-46e8-b5b6-1ce015c3dbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
